import sys
import pandas as pd
import numpy as np
import json


def load_data(filepath, selected_features=None):
    """Charge les donnÃ©es depuis le CSV et extrait X et y"""
    # 1. Charger le CSV
    try:
        df = pd.read_csv(filepath)
        print(f"âœ… Fichier chargÃ© : {filepath}")
        print(f"   {len(df)} Ã©tudiants trouvÃ©s")
    except FileNotFoundError:
        print(f"âŒ Erreur : Le fichier {filepath} n'existe pas")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ Erreur lors du chargement : {e}")
        sys.exit(1)

    # 2. Extraire y (labels - les maisons)
    if 'Hogwarts House' not in df.columns:
        print("âŒ Erreur : Colonne 'Hogwarts House' introuvable")
        sys.exit(1)

    y = df['Hogwarts House'].copy()

    # VÃ©rifier qu'il n'y a pas de NaN dans y
    nan_count = y.isna().sum()
    if nan_count > 0:
        print(f"âš ï¸  Attention : {nan_count} valeurs manquantes dans "
              f"'Hogwarts House'")
        # On retire les lignes avec NaN dans y
        valid_indices = y.notna()
        y = y[valid_indices]
        df = df[valid_indices]
        print(f"   â†’ {len(y)} Ã©tudiants conservÃ©s aprÃ¨s nettoyage")

    # 3. Extraire X (features - les cours)
    # Colonnes Ã  exclure (non-numÃ©riques ou non-pertinentes)
    non_feature_columns = ['Index', 'Hogwarts House', 'First Name',
                           'Last Name', 'Birthday', 'Best Hand']

    # DÃ©terminer les features Ã  utiliser
    if selected_features is not None:
        # Utiliser les features sÃ©lectionnÃ©es (d'aprÃ¨s l'analyse EDA)
        feature_columns = selected_features
        print("ğŸ¯ Utilisation des features sÃ©lectionnÃ©es (analyse EDA)")
    else:
        # Utiliser toutes les colonnes numÃ©riques
        feature_columns = []
        for col in df.columns:
            if col not in non_feature_columns:
                # VÃ©rifier que c'est bien numÃ©rique
                if df[col].dtype in ['float64', 'int64']:
                    feature_columns.append(col)
        print("ğŸ“Š Utilisation de toutes les features numÃ©riques")

    if len(feature_columns) == 0:
        print("âŒ Erreur : Aucune feature numÃ©rique trouvÃ©e")
        sys.exit(1)

    # VÃ©rifier que toutes les features demandÃ©es existent
    for col in feature_columns:
        if col not in df.columns:
            print(f"âŒ Erreur : Feature '{col}' introuvable dans le dataset")
            sys.exit(1)

    # Convertir X en numpy array pour les calculs matriciels
    X = df[feature_columns].values

    print(f"âœ… Features sÃ©lectionnÃ©es : {len(feature_columns)} cours")
    for i, feat in enumerate(feature_columns, 1):
        print(f"   {i}. {feat}")
    print(f"\nâœ… Labels : {y.nunique()} maisons")
    print(f"   {sorted(y.unique())}")
    print(f"\nğŸ“ Shape de X : {X.shape} (samples, features)")

    return X, y, feature_columns


def handle_missing_values(X):
    """Remplace les valeurs manquantes (NaN) par la moyenne de leur colonne"""
    # CrÃ©er une copie pour ne pas modifier l'original
    X_clean = X.copy()

    m, n = X.shape  # m = nombre d'Ã©tudiants, n = nombre de features
    total_nans = 0

    # Pour chaque colonne (chaque feature)
    for j in range(n):
        # Extraire la colonne j
        column = X[:, j]

        # Calculer la moyenne
        total = 0.0
        count = 0

        # Parcourir toutes les valeurs de la colonne
        for i in range(m):
            val = column[i]
            # VÃ©rifier si c'est un NaN
            if not np.isnan(val):
                total += val
                count += 1

        # Si toute la colonne est NaN
        if count == 0:
            mean = 0.0
            print(f"âš ï¸  Colonne {j} entiÃ¨rement NaN â†’ moyenne = 0")
        else:
            mean = total / count

        # Compter et remplacer les NaN dans cette colonne
        # Utiliser un masque boolÃ©en pour identifier les NaN
        nan_mask = np.isnan(X_clean[:, j])
        nan_count = np.sum(nan_mask)

        if nan_count > 0:
            # Remplacer tous les NaN de cette colonne par la moyenne
            X_clean[nan_mask, j] = mean
            total_nans += nan_count

    print(f"âœ… Valeurs manquantes traitÃ©es : {total_nans} NaN remplacÃ©s")
    if total_nans > 0:
        print("   StratÃ©gie : remplacement par la moyenne de chaque colonne")

    return X_clean


def standardize(X):
    """Standardise les donnÃ©es avec le z-score (normalisation)
    Description:
        Pour chaque colonne :
        1. Calculer manuellement la moyenne Î¼
        2. Calculer manuellement l'Ã©cart-type Ïƒ
           Ïƒ = âˆš(Î£(x - Î¼)Â² / m)
        3. Normaliser : x_norm = (x - Î¼) / Ïƒ
    """
    m, n = X.shape
    X_norm = X.copy()

    # Tableaux pour stocker les moyennes et Ã©carts-types
    means = np.zeros(n)
    stds = np.zeros(n)

    # Pour chaque colonne (chaque feature)
    for j in range(n):
        column = X[:, j]

        # 1. Calculer la moyenne
        total = 0.0
        for i in range(m):
            total += column[i]
        mean = total / m
        means[j] = mean

        # 2. Calculer l'Ã©cart-type
        # std = âˆš(Î£(x - mean)Â² / m)
        sum_squared_diff = 0.0
        for i in range(m):
            diff = column[i] - mean
            sum_squared_diff += diff * diff

        variance = sum_squared_diff / m
        std = variance ** 0.5  # Racine carrÃ©e
        stds[j] = std

        # 3. Normaliser la colonne
        # Si std = 0 (colonne constante), on ne divise pas pour Ã©viter NaN
        if std > 0:
            X_norm[:, j] = (column - mean) / std
        else:
            # Colonne constante â†’ on centre juste (- mean)
            X_norm[:, j] = column - mean
            print(f"âš ï¸  Colonne {j} a un Ã©cart-type nul â†’ centrÃ©e seulement")

    print("âœ… Standardisation terminÃ©e (z-score)")
    print(f"   Moyennes : min={means.min():.2f}, max={means.max():.2f}")
    print(f"   Ã‰carts-types : min={stds.min():.2f}, max={stds.max():.2f}")
    print(f"   X_norm : min={X_norm.min():.2f}, max={X_norm.max():.2f}")

    return X_norm, means, stds


def add_intercept(X):
    """
    Ajoute une colonne de 1 au dÃ©but de la matrice X (intercept/biais)

    Description:
        Ajoute une colonne de 1 tout Ã  gauche de X.
        Cette colonne permet de calculer le terme d'intercept (Î¸â‚€)
        automatiquement dans le produit matriciel z = X @ Î¸

        Exemple:
            X = [[x1, x2],     â†’    X_intercept = [[1, x1, x2],
                 [x3, x4]]                          [1, x3, x4]]

        Shape : (m, n) â†’ (m, n+1)
    """
    m = X.shape[0]  # Nombre d'Ã©chantillons

    # CrÃ©er une colonne de 1 de taille (m,)
    ones = np.ones(m)

    # ConcatÃ©ner horizontalement : [colonne de 1] + [X]
    # np.c_ permet de concatÃ©ner des colonnes
    X_with_intercept = np.c_[ones, X]

    print("âœ… Colonne d'intercept ajoutÃ©e")
    print(f"   Shape avant : {X.shape}")
    print(f"   Shape aprÃ¨s : {X_with_intercept.shape}")

    return X_with_intercept


def main():
    """Point d'entrÃ©e principal du programme"""
    # RÃ©cupÃ©rer le fichier
    if len(sys.argv) > 1:
        filepath = sys.argv[1]
    else:
        filepath = 'data/dataset_train.csv'

    print("=" * 60)
    print("âš¡ POUDLARD - ENTRAÃNEMENT DU MODÃˆLE âš¡")
    print("=" * 60)
    print()

    # Ã‰tape 1 : Charger les donnÃ©es
    print("ğŸ“‚ Ã‰TAPE 1/4 : Chargement des donnÃ©es")
    print("-" * 60)

    # Option 1 : Utiliser toutes les features (par dÃ©faut)
    X, y, feature_names = load_data(filepath)

    # Option 2 : Utiliser seulement les meilleures features (d'aprÃ¨s pair_plot)
    # D'aprÃ¨s ton analyse, tu pourrais sÃ©lectionner par exemple :
    # selected = ['Herbology', 'Ancient Runes', 'Astronomy',
    #             'Defense Against the Dark Arts']
    # X, y, feature_names = load_data(filepath, selected_features=selected)

    print()

    # Ã‰tape 2 : GÃ©rer les NaN
    print("ğŸ”§ Ã‰TAPE 2/4 : Gestion des valeurs manquantes")
    print("-" * 60)
    X = handle_missing_values(X)
    # VÃ©rification : plus aucun NaN
    remaining_nans = np.sum(np.isnan(X))
    if remaining_nans == 0:
        print("âœ… VÃ©rification : 0 NaN restant dans X")
    else:
        print(f"âš ï¸  Attention : {remaining_nans} NaN encore prÃ©sents!")
    print()

    # Ã‰tape 3 : Standardiser (normalisation z-score)
    print("ğŸ“Š Ã‰TAPE 3/4 : Standardisation (z-score)")
    print("-" * 60)
    X, means, stds = standardize(X)
    print()

    # Ã‰tape 4 : Ajouter la colonne d'intercept
    print("â• Ã‰TAPE 4/4 : Ajout de la colonne d'intercept")
    print("-" * 60)
    X = add_intercept(X)
    print()

    print("=" * 60)
    print("âœ… PRÃ‰PARATION DES DONNÃ‰ES TERMINÃ‰E")
    print("=" * 60)
    print(f"   Shape finale de X : {X.shape}")
    print(f"   Nombre d'Ã©chantillons : {X.shape[0]}")
    print(f"   Nombre de features (+intercept) : {X.shape[1]}")
    print()

    # TODO : Ã‰tape 5 - EntraÃ®ner le modÃ¨le
    # TODO : Ã‰tape 6 - Sauvegarder les poids


if __name__ == '__main__':
    main()
